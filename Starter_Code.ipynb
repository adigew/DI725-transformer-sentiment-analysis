{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0e259e7b-d05b-41b8-b596-6ecdd4866c60",
   "metadata": {},
   "source": [
    "# DI 725: Transformers and Attention-Based Deep Networks\n",
    "\n",
    "## An Assignment for Implementing Transformers in PyTorch\n",
    "\n",
    "The purpose of this notebook is to guide you through the usage of sample code.\n",
    "\n",
    "This notebook follows the baseline prepared by Andrej Karpathy, with a custom dataset (Don-Quixote by Cervantes). This version of the code, called [nanoGPT](https://github.com/karpathy/nanoGPT), is a revisit to his famous [minGPT](https://github.com/karpathy/minGPT).\n",
    "### Author:\n",
    "* Ümit Mert Çağlar\n",
    "### Assignee:\n",
    "* Nesil Bor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715be989-8426-4406-bd8f-2bcf0e003f09",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "Install requirements for your environment, comment out for later uses.\n",
    "\n",
    "Dependencies:\n",
    "\n",
    "- [pytorch](https://pytorch.org)\n",
    "- [numpy](https://numpy.org/install/)\n",
    "-  `transformers` for huggingface transformers (to load GPT-2 checkpoints)\n",
    "-  `datasets` for huggingface datasets (to download + preprocess datasets)\n",
    "-  `tiktoken` for OpenAI's fast BPE code\n",
    "-  `wandb` for optional logging\n",
    "-  `tqdm` for progress bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69136d40-c5ac-4623-899c-3b5ad21f368c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (2.6.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (2.2.4)\n",
      "Requirement already satisfied: transformers in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (4.49.0)\n",
      "Requirement already satisfied: datasets in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (3.5.0)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (0.9.0)\n",
      "Requirement already satisfied: wandb in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (0.18.7)\n",
      "Requirement already satisfied: tqdm in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (4.67.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch) (4.13.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch) (78.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (0.27.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from datasets) (3.11.16)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from wandb) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from wandb) (4.3.6)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from wandb) (5.29.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from wandb) (6.1.0)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from wandb) (2.19.0)\n",
      "Requirement already satisfied: setproctitle in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from wandb) (1.3.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: six>=1.4.0 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from aiohttp->datasets) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from aiohttp->datasets) (6.3.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from aiohttp->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\nesil.bor\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
     ]
    }
   ],
   "source": [
    "#!pip install numpy transformers datasets tiktoken wandb tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01777420",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip uninstall torch\n",
    "#!pip install torch --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0aa90f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu121\n",
      "True\n",
      "12.1\n",
      "0\n",
      "NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e72d12-9aa6-456f-ae34-2c52aaeee7c3",
   "metadata": {},
   "source": [
    "The fastest way to get started to transformers, apart from following the labs of DI725, is to use a small model and dataset. For this purpose, we will start with training a character-level GPT on the Don-Quixote by Cervantes. The code will download a single file (2MB) and apply some transformations. Examine the code [prepare.py](data/don_char/prepare.py)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dfa2cade-4742-4b44-bcb2-0ae72c9571ad",
   "metadata": {},
   "source": [
    "## The first model for sentiment analysis with own custom model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6869a547-0ebb-4be6-9b25-f158db64407e",
   "metadata": {},
   "source": [
    "This first model for sentiment analysis after training. Use the following to prepare the customer service in custom own first model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17a08a93-5556-4cd9-ad2d-cc58d0363d52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train class distribution:\n",
      "sentiment\n",
      "1    542\n",
      "0    411\n",
      "2     17\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test class distribution:\n",
      "sentiment\n",
      "0    10\n",
      "1    10\n",
      "2    10\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Data processing complete:\n",
      "- Training samples: 776\n",
      "- Validation samples: 194\n",
      "- Test samples: 30\n",
      "Data saved to: c:\\Users\\nesil.bor\\Desktop\\Folders\\master\\DI725\\DI725-transformer-sentiment-analysis\\data\\sentiment\\processed\n",
      "\n",
      "Verifying saved files:\n",
      "- train.bin: 794624 bytes\n",
      "- val.bin: 198656 bytes\n",
      "- test.bin: 30720 bytes\n",
      "- train_labels.pkl: 928 bytes\n",
      "- val_labels.pkl: 342 bytes\n",
      "- test_labels.pkl: 178 bytes\n"
     ]
    }
   ],
   "source": [
    "!python data/sentiment/prepare.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "56a34276-d844-435d-9e16-12f567969d5f",
   "metadata": {},
   "source": [
    "This creates a `train.bin`,`val.bin` and `test.bin` in that data directory. Now it is time to train our own GPT. The size of the GPT model depends on the computational resources. It is advised to have a GPU for heavy works, and to train lightweight and evaluate and infer models with a CPU.\n",
    "\n",
    "Small scale GPT with the settings provided in the [config/train_sentiment.py](config/train_sentiment.py) config file will be trained with the following code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ad3097d-65d8-4a72-a8d0-b5fa463b49c8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loaded train dataset: 776 samples\n",
      "Loaded val dataset: 194 samples\n",
      "DataLoaders initialized\n",
      "W&B initialized in online mode. View live at: https://wandb.ai/<your-username>/nanoGPT-sentiment\n",
      "Model moved to device\n",
      "Optimizer initialized\n",
      "Starting training loop\n",
      "Iter 0, Loss: 1.2051, Accuracy: 0.3125, Data: 0.024s, Forward: 0.179s, Backward: 0.189s, Total: 0.391s\n",
      "Validation Loss: 1.0309, Validation Accuracy: 0.4375\n",
      "Iter 50, Loss: 0.4992, Accuracy: 0.8125, Data: 0.000s, Forward: 0.011s, Backward: 0.123s, Total: 0.134s\n",
      "Iter 100, Loss: 0.3244, Accuracy: 0.8125, Data: 0.000s, Forward: 0.006s, Backward: 0.120s, Total: 0.126s\n",
      "Validation Loss: 0.6222, Validation Accuracy: 0.7625\n",
      "Iter 150, Loss: 0.4103, Accuracy: 0.8750, Data: 0.000s, Forward: 0.005s, Backward: 0.123s, Total: 0.128s\n",
      "Iter 200, Loss: 0.0325, Accuracy: 1.0000, Data: 0.000s, Forward: 0.005s, Backward: 0.125s, Total: 0.130s\n",
      "Validation Loss: 0.3112, Validation Accuracy: 0.8875\n",
      "Iter 250, Loss: 0.1596, Accuracy: 0.9375, Data: 0.000s, Forward: 0.005s, Backward: 0.125s, Total: 0.130s\n",
      "Iter 300, Loss: 0.2218, Accuracy: 0.9375, Data: 0.001s, Forward: 0.005s, Backward: 0.122s, Total: 0.127s\n",
      "Validation Loss: 0.2826, Validation Accuracy: 0.9125\n",
      "Iter 350, Loss: 0.2531, Accuracy: 0.9375, Data: 0.000s, Forward: 0.005s, Backward: 0.124s, Total: 0.129s\n",
      "Iter 400, Loss: 0.0209, Accuracy: 1.0000, Data: 0.001s, Forward: 0.004s, Backward: 0.123s, Total: 0.128s\n",
      "Validation Loss: 0.3723, Validation Accuracy: 0.9062\n",
      "Patience counter: 1/2\n",
      "Iter 450, Loss: 0.0545, Accuracy: 1.0000, Data: 0.000s, Forward: 0.006s, Backward: 0.122s, Total: 0.128s\n",
      "Iter 500, Loss: 0.0049, Accuracy: 1.0000, Data: 0.000s, Forward: 0.005s, Backward: 0.123s, Total: 0.128s\n",
      "Validation Loss: 0.6000, Validation Accuracy: 0.8750\n",
      "Patience counter: 2/2\n",
      "Early stopping triggered. Stopping training.\n",
      "Training complete. View results at: https://wandb.ai/<your-username>/nanoGPT-sentiment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: Currently logged in as: adigew (adigew-middle-east-technical-university). Use `wandb login --relogin` to force relogin\n",
      "wandb: Tracking run with wandb version 0.18.7\n",
      "wandb: Run data is saved locally in c:\\Users\\nesil.bor\\Desktop\\Folders\\master\\DI725\\DI725-transformer-sentiment-analysis\\wandb\\run-20250405_165123-be2r9po8\n",
      "wandb: Run `wandb offline` to turn off syncing.\n",
      "wandb: Syncing run andorian-nimoy-36\n",
      "wandb:  View project at https://wandb.ai/adigew-middle-east-technical-university/nanoGPT-sentiment\n",
      "wandb:  View run at https://wandb.ai/adigew-middle-east-technical-university/nanoGPT-sentiment/runs/be2r9po8\n",
      "wandb:                                                                                \n",
      "wandb: \n",
      "wandb: Run history:\n",
      "wandb:  backward_time █▁▁▁▁▁▁▁▁▁▁\n",
      "wandb:      data_time █▁▁▁▁▁▁▁▁▁▁\n",
      "wandb:   forward_time █▁▁▁▁▁▁▁▁▁▁\n",
      "wandb:      iteration ▁▁▂▂▂▃▄▄▅▅▅▆▇▇▇██\n",
      "wandb:  learning_rate ▁▅████▇▇▆▆▅\n",
      "wandb: train_accuracy ▁▆▆▇█▇▇▇███\n",
      "wandb:     train_loss █▄▃▃▁▂▂▂▁▁▁\n",
      "wandb:   val_accuracy ▁▆███▇\n",
      "wandb:       val_loss █▄▁▁▂▄\n",
      "wandb: \n",
      "wandb: Run summary:\n",
      "wandb:  backward_time 0.12345\n",
      "wandb:      data_time 0\n",
      "wandb:   forward_time 0.00471\n",
      "wandb:      iteration 500\n",
      "wandb:  learning_rate 0.00011\n",
      "wandb: train_accuracy 1\n",
      "wandb:     train_loss 0.00489\n",
      "wandb:   val_accuracy 0.875\n",
      "wandb:       val_loss 0.60001\n",
      "wandb: \n",
      "wandb:  View run andorian-nimoy-36 at: https://wandb.ai/adigew-middle-east-technical-university/nanoGPT-sentiment/runs/be2r9po8\n",
      "wandb:  View project at: https://wandb.ai/adigew-middle-east-technical-university/nanoGPT-sentiment\n",
      "wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "wandb: Find logs at: .\\wandb\\run-20250405_165123-be2r9po8\\logs\n"
     ]
    }
   ],
   "source": [
    "!python train.py --config=config/train_sentiment.py --compile=False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7a06da9f-a5a1-4621-806c-adad9b2d98d5",
   "metadata": {},
   "source": [
    "We are training a small scaled GPT with a context size of up to 512 characters, 384 feature channels, 6 layers of transformer with 6 attention heads. On one GTX 3060 GPU this training run takes about 3 minutes and the best validation loss is 0.2826. Based on the configuration, the model checkpoints are being written into the `--out_dir` directory `out-sentiment`. So once the training finishes we can sample from the best model by pointing the sampling script at this directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d3380c5-976e-4dbb-b5dc-08ba56f0d93c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from out-sentiment\\best_model.pt and moved to cuda\n",
      "Loaded test dataset: 30 samples\n",
      "\n",
      "Sample 1:\n",
      "Text: thank you for calling brownbox customer support  my name is sarah  how may i assist you today? hi  s...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.014343023300170898, 0.9666900038719177, 0.018967006355524063])\n",
      "True Sentiment: Negative\n",
      "\n",
      "Sample 2:\n",
      "Text: thank you for calling brownbox customer support  my name is sarah  how can i assist you today? hi sa...\n",
      "Predicted Sentiment: Negative (Probabilities: [0.9675621390342712, 0.01856013759970665, 0.013877768069505692])\n",
      "True Sentiment: Negative\n",
      "\n",
      "Sample 3:\n",
      "Text: thank you for calling brownbox customer support  my name is jane  how may i assist you today? hi jan...\n",
      "Predicted Sentiment: Negative (Probabilities: [0.9681538939476013, 0.014998635277152061, 0.016847506165504456])\n",
      "True Sentiment: Negative\n",
      "\n",
      "Sample 4:\n",
      "Text: thank you for calling brownbox customer support  my name is sarah  how may i assist you today? hi sa...\n",
      "Predicted Sentiment: Negative (Probabilities: [0.9677400588989258, 0.01380248460918665, 0.018457522615790367])\n",
      "True Sentiment: Negative\n",
      "\n",
      "Sample 5:\n",
      "Text: thank you for calling brownbox customer support  my name is sarah  how may i assist you today? hi sa...\n",
      "Predicted Sentiment: Negative (Probabilities: [0.9659473896026611, 0.02338007465004921, 0.010672609321773052])\n",
      "True Sentiment: Negative\n",
      "\n",
      "Sample 6:\n",
      "Text: thank you for calling brownbox customer support  my name is rachel  how may i assist you today? hi r...\n",
      "Predicted Sentiment: Negative (Probabilities: [0.9684048891067505, 0.015901243314146996, 0.01569392718374729])\n",
      "True Sentiment: Negative\n",
      "\n",
      "Sample 7:\n",
      "Text: thank you for calling brownbox customer support  my name is john  how may i assist you today? hi joh...\n",
      "Predicted Sentiment: Negative (Probabilities: [0.9674580097198486, 0.0187771487981081, 0.013764815405011177])\n",
      "True Sentiment: Negative\n",
      "\n",
      "Sample 8:\n",
      "Text: thank you for calling brownbox customer support  my name is alex  how may i assist you today? hi  al...\n",
      "Predicted Sentiment: Negative (Probabilities: [0.967836320400238, 0.016475636512041092, 0.015688026323914528])\n",
      "True Sentiment: Negative\n",
      "\n",
      "Sample 9:\n",
      "Text: hello  thank you for contacting brownbox customer support  how may i assist you today? hi  i am extr...\n",
      "Predicted Sentiment: Negative (Probabilities: [0.9692482352256775, 0.016512494534254074, 0.014239216223359108])\n",
      "True Sentiment: Negative\n",
      "\n",
      "Sample 10:\n",
      "Text: thank you for calling brownbox customer support  my name is sarah  how may i assist you today? hi sa...\n",
      "Predicted Sentiment: Negative (Probabilities: [0.9668374061584473, 0.021341143175959587, 0.011821426451206207])\n",
      "True Sentiment: Negative\n",
      "\n",
      "Sample 11:\n",
      "Text: hello  i was looking to buy a vacuum cleaner from your website  but the one i want is currently out ...\n",
      "Predicted Sentiment: Negative (Probabilities: [0.9649214148521423, 0.022164858877658844, 0.012913726270198822])\n",
      "True Sentiment: Neutral\n",
      "\n",
      "Sample 12:\n",
      "Text: thank you for calling brownbox customer support  my name is sarah  how may i assist you today? hi sa...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.21488188207149506, 0.7751970291137695, 0.009921101853251457])\n",
      "True Sentiment: Neutral\n",
      "\n",
      "Sample 13:\n",
      "Text: thank you for calling brownbox customer support  my name is emily  how may i assist you today? hi  e...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.012044432573020458, 0.9645727872848511, 0.02338281087577343])\n",
      "True Sentiment: Neutral\n",
      "\n",
      "Sample 14:\n",
      "Text: thank you for contacting brownbox customer support  my name is john  how can i assist you today? hi ...\n",
      "Predicted Sentiment: Negative (Probabilities: [0.5884491205215454, 0.40249398350715637, 0.009056853130459785])\n",
      "True Sentiment: Neutral\n",
      "\n",
      "Sample 15:\n",
      "Text: hi  i have a question about return checks and fees for a vacuum cleaner i returned  hello thank you ...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.009507699869573116, 0.9383330345153809, 0.052159324288368225])\n",
      "True Sentiment: Neutral\n",
      "\n",
      "Sample 16:\n",
      "Text: hello  thank you for calling brownbox customer support  my name is john  how may i assist you today?...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.012607245706021786, 0.96037358045578, 0.02701917663216591])\n",
      "True Sentiment: Neutral\n",
      "\n",
      "Sample 17:\n",
      "Text: thank you for reaching out to brownbox customer support  how may i assist you today? hi  i received ...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.009854378178715706, 0.9522823095321655, 0.03786338493227959])\n",
      "True Sentiment: Neutral\n",
      "\n",
      "Sample 18:\n",
      "Text: hello  thank you for calling brownbox customer support  my name is sarah  how may i assist you today...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.012118501588702202, 0.9611547589302063, 0.026726752519607544])\n",
      "True Sentiment: Neutral\n",
      "\n",
      "Sample 19:\n",
      "Text: thank you for calling brownbox customer support  my name is rachel  how may i assist you today? hi  ...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.014383320696651936, 0.9655731320381165, 0.020043494179844856])\n",
      "True Sentiment: Neutral\n",
      "\n",
      "Sample 20:\n",
      "Text: thank you for contacting brownbox customer support  my name is rachel  how may i assist you today? h...\n",
      "Predicted Sentiment: Positive (Probabilities: [0.013944830745458603, 0.3356749415397644, 0.6503801941871643])\n",
      "True Sentiment: Neutral\n",
      "\n",
      "Sample 21:\n",
      "Text: thank you for calling brownbox customer support  my name is sarah  how can i assist you today? hi sa...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.013115031644701958, 0.6537413001060486, 0.3331436514854431])\n",
      "True Sentiment: Positive\n",
      "\n",
      "Sample 22:\n",
      "Text: thank you for calling brownbox customer support  my name is emily  how may i assist you today? hi em...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.010757780633866787, 0.7822187542915344, 0.20702342689037323])\n",
      "True Sentiment: Positive\n",
      "\n",
      "Sample 23:\n",
      "Text: thank you for calling brownbox customer support  my name is alex  how may i assist you today? hi ale...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.00927333626896143, 0.7832661271095276, 0.20746049284934998])\n",
      "True Sentiment: Positive\n",
      "\n",
      "Sample 24:\n",
      "Text: thank you for calling brownbox customer support  my name is sarah  how can i assist you today? hi sa...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.009479166939854622, 0.8296710252761841, 0.16084976494312286])\n",
      "True Sentiment: Positive\n",
      "\n",
      "Sample 25:\n",
      "Text: hi  i placed an order for a vacuum cleaner yesterday  and i just wanted to confirm the order status ...\n",
      "Predicted Sentiment: Positive (Probabilities: [0.03107735700905323, 0.10802832990884781, 0.8608942627906799])\n",
      "True Sentiment: Positive\n",
      "\n",
      "Sample 26:\n",
      "Text: hi  i'm calling to inquire about my order status for a smart band i purchased from brownbox  hello t...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.013210558332502842, 0.7325469851493835, 0.2542424499988556])\n",
      "True Sentiment: Positive\n",
      "\n",
      "Sample 27:\n",
      "Text: thank you for calling brownbox customer support  my name is john  how may i assist you today? hi joh...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.010288374498486519, 0.6705073714256287, 0.3192042112350464])\n",
      "True Sentiment: Positive\n",
      "\n",
      "Sample 28:\n",
      "Text: hi there  i'm interested in purchasing a dslr camera from your website  but i'm having trouble findi...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.009211595170199871, 0.8274405598640442, 0.16334787011146545])\n",
      "True Sentiment: Positive\n",
      "\n",
      "Sample 29:\n",
      "Text: thank you for calling brownbox customer support  my name is sarah  how may i assist you today? hi sa...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.012707988731563091, 0.6062231659889221, 0.3810688257217407])\n",
      "True Sentiment: Positive\n",
      "\n",
      "Sample 30:\n",
      "Text: thank you for calling brownbox customer support  this is john  how may i assist you today? hi john  ...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.009586544707417488, 0.9364312291145325, 0.05398227646946907])\n",
      "True Sentiment: Positive\n",
      "\n",
      "Summary: 17/30 correct, Test Accuracy: 0.5667 (56.67%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nesil.bor\\Desktop\\Folders\\master\\DI725\\DI725-transformer-sentiment-analysis\\sample1.py:31: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n"
     ]
    }
   ],
   "source": [
    "!python sample.py --out_dir=out-sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b5d51e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from out-sentiment\\final_model.pt and moved to cuda\n",
      "Loaded test dataset: 30 samples\n",
      "\n",
      "Sample 1:\n",
      "Text: thank you for calling brownbox customer support  my name is sarah  how may i assist you today? hi  s...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.021121535450220108, 0.9692690968513489, 0.009609431959688663])\n",
      "True Sentiment: Negative\n",
      "\n",
      "Sample 2:\n",
      "Text: thank you for calling brownbox customer support  my name is sarah  how can i assist you today? hi sa...\n",
      "Predicted Sentiment: Negative (Probabilities: [0.9722861647605896, 0.014958624728024006, 0.012755151838064194])\n",
      "True Sentiment: Negative\n",
      "\n",
      "Sample 3:\n",
      "Text: thank you for calling brownbox customer support  my name is jane  how may i assist you today? hi jan...\n",
      "Predicted Sentiment: Negative (Probabilities: [0.9721629023551941, 0.013804925605654716, 0.01403222605586052])\n",
      "True Sentiment: Negative\n",
      "\n",
      "Sample 4:\n",
      "Text: thank you for calling brownbox customer support  my name is sarah  how may i assist you today? hi sa...\n",
      "Predicted Sentiment: Negative (Probabilities: [0.972852885723114, 0.012265088967978954, 0.014881979674100876])\n",
      "True Sentiment: Negative\n",
      "\n",
      "Sample 5:\n",
      "Text: thank you for calling brownbox customer support  my name is sarah  how may i assist you today? hi sa...\n",
      "Predicted Sentiment: Negative (Probabilities: [0.9711194038391113, 0.019059134647250175, 0.009821501560509205])\n",
      "True Sentiment: Negative\n",
      "\n",
      "Sample 6:\n",
      "Text: thank you for calling brownbox customer support  my name is rachel  how may i assist you today? hi r...\n",
      "Predicted Sentiment: Negative (Probabilities: [0.9723978638648987, 0.013634459115564823, 0.013967698439955711])\n",
      "True Sentiment: Negative\n",
      "\n",
      "Sample 7:\n",
      "Text: thank you for calling brownbox customer support  my name is john  how may i assist you today? hi joh...\n",
      "Predicted Sentiment: Negative (Probabilities: [0.9709190130233765, 0.017280759289860725, 0.011800277978181839])\n",
      "True Sentiment: Negative\n",
      "\n",
      "Sample 8:\n",
      "Text: thank you for calling brownbox customer support  my name is alex  how may i assist you today? hi  al...\n",
      "Predicted Sentiment: Negative (Probabilities: [0.9721490740776062, 0.014803759753704071, 0.013047182001173496])\n",
      "True Sentiment: Negative\n",
      "\n",
      "Sample 9:\n",
      "Text: hello  thank you for contacting brownbox customer support  how may i assist you today? hi  i am extr...\n",
      "Predicted Sentiment: Negative (Probabilities: [0.9727766513824463, 0.014852874912321568, 0.012370445765554905])\n",
      "True Sentiment: Negative\n",
      "\n",
      "Sample 10:\n",
      "Text: thank you for calling brownbox customer support  my name is sarah  how may i assist you today? hi sa...\n",
      "Predicted Sentiment: Negative (Probabilities: [0.9721810221672058, 0.016411172226071358, 0.011407794430851936])\n",
      "True Sentiment: Negative\n",
      "\n",
      "Sample 11:\n",
      "Text: hello  i was looking to buy a vacuum cleaner from your website  but the one i want is currently out ...\n",
      "Predicted Sentiment: Negative (Probabilities: [0.9713521599769592, 0.0177485179156065, 0.010899403132498264])\n",
      "True Sentiment: Neutral\n",
      "\n",
      "Sample 12:\n",
      "Text: thank you for calling brownbox customer support  my name is sarah  how may i assist you today? hi sa...\n",
      "Predicted Sentiment: Negative (Probabilities: [0.598780632019043, 0.3930101692676544, 0.008209219202399254])\n",
      "True Sentiment: Neutral\n",
      "\n",
      "Sample 13:\n",
      "Text: thank you for calling brownbox customer support  my name is emily  how may i assist you today? hi  e...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.012473350390791893, 0.9498487114906311, 0.03767797723412514])\n",
      "True Sentiment: Neutral\n",
      "\n",
      "Sample 14:\n",
      "Text: thank you for contacting brownbox customer support  my name is john  how can i assist you today? hi ...\n",
      "Predicted Sentiment: Negative (Probabilities: [0.8204224109649658, 0.17216452956199646, 0.0074130576103925705])\n",
      "True Sentiment: Neutral\n",
      "\n",
      "Sample 15:\n",
      "Text: hi  i have a question about return checks and fees for a vacuum cleaner i returned  hello thank you ...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.009847376495599747, 0.9660844802856445, 0.024068113416433334])\n",
      "True Sentiment: Neutral\n",
      "\n",
      "Sample 16:\n",
      "Text: hello  thank you for calling brownbox customer support  my name is john  how may i assist you today?...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.015107812359929085, 0.9720813632011414, 0.012810845859348774])\n",
      "True Sentiment: Neutral\n",
      "\n",
      "Sample 17:\n",
      "Text: thank you for reaching out to brownbox customer support  how may i assist you today? hi  i received ...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.008577778935432434, 0.9580582976341248, 0.033363889902830124])\n",
      "True Sentiment: Neutral\n",
      "\n",
      "Sample 18:\n",
      "Text: hello  thank you for calling brownbox customer support  my name is sarah  how may i assist you today...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.0176861435174942, 0.971189558506012, 0.011124297976493835])\n",
      "True Sentiment: Neutral\n",
      "\n",
      "Sample 19:\n",
      "Text: thank you for calling brownbox customer support  my name is rachel  how may i assist you today? hi  ...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.017615124583244324, 0.9714636206626892, 0.010921203531324863])\n",
      "True Sentiment: Neutral\n",
      "\n",
      "Sample 20:\n",
      "Text: thank you for contacting brownbox customer support  my name is rachel  how may i assist you today? h...\n",
      "Predicted Sentiment: Positive (Probabilities: [0.0137924924492836, 0.3823683559894562, 0.603839099407196])\n",
      "True Sentiment: Neutral\n",
      "\n",
      "Sample 21:\n",
      "Text: thank you for calling brownbox customer support  my name is sarah  how can i assist you today? hi sa...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.011881017126142979, 0.9141932725906372, 0.07392578572034836])\n",
      "True Sentiment: Positive\n",
      "\n",
      "Sample 22:\n",
      "Text: thank you for calling brownbox customer support  my name is emily  how may i assist you today? hi em...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.0104841822758317, 0.8431772589683533, 0.14633852243423462])\n",
      "True Sentiment: Positive\n",
      "\n",
      "Sample 23:\n",
      "Text: thank you for calling brownbox customer support  my name is alex  how may i assist you today? hi ale...\n",
      "Predicted Sentiment: Positive (Probabilities: [0.011913419701159, 0.28075897693634033, 0.7073276042938232])\n",
      "True Sentiment: Positive\n",
      "\n",
      "Sample 24:\n",
      "Text: thank you for calling brownbox customer support  my name is sarah  how can i assist you today? hi sa...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.009638515301048756, 0.8906351923942566, 0.09972625225782394])\n",
      "True Sentiment: Positive\n",
      "\n",
      "Sample 25:\n",
      "Text: hi  i placed an order for a vacuum cleaner yesterday  and i just wanted to confirm the order status ...\n",
      "Predicted Sentiment: Positive (Probabilities: [0.03850914165377617, 0.23096208274364471, 0.7305287718772888])\n",
      "True Sentiment: Positive\n",
      "\n",
      "Sample 26:\n",
      "Text: hi  i'm calling to inquire about my order status for a smart band i purchased from brownbox  hello t...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.010958738625049591, 0.8338408470153809, 0.15520046651363373])\n",
      "True Sentiment: Positive\n",
      "\n",
      "Sample 27:\n",
      "Text: thank you for calling brownbox customer support  my name is john  how may i assist you today? hi joh...\n",
      "Predicted Sentiment: Positive (Probabilities: [0.013164668343961239, 0.1933564692735672, 0.7934789061546326])\n",
      "True Sentiment: Positive\n",
      "\n",
      "Sample 28:\n",
      "Text: hi there  i'm interested in purchasing a dslr camera from your website  but i'm having trouble findi...\n",
      "Predicted Sentiment: Positive (Probabilities: [0.01256250124424696, 0.45124536752700806, 0.5361921191215515])\n",
      "True Sentiment: Positive\n",
      "\n",
      "Sample 29:\n",
      "Text: thank you for calling brownbox customer support  my name is sarah  how may i assist you today? hi sa...\n",
      "Predicted Sentiment: Positive (Probabilities: [0.014021523296833038, 0.41733318567276, 0.5686452984809875])\n",
      "True Sentiment: Positive\n",
      "\n",
      "Sample 30:\n",
      "Text: thank you for calling brownbox customer support  this is john  how may i assist you today? hi john  ...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.009082639589905739, 0.9250823855400085, 0.06583504378795624])\n",
      "True Sentiment: Positive\n",
      "\n",
      "Summary: 20/30 correct, Test Accuracy: 0.6667 (66.67%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nesil.bor\\Desktop\\Folders\\master\\DI725\\DI725-transformer-sentiment-analysis\\sample1.py:31: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n"
     ]
    }
   ],
   "source": [
    "!python sample.py --out_dir=out-sentiment --checkpoint=final_model.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b323fd-20ba-4e6b-8a5a-e40b9fdd0bca",
   "metadata": {},
   "source": [
    "## Quick start with less resources\n",
    "\n",
    "If we are [low on resources](https://www.youtube.com/watch?v=rcXzn6xXdIc), we can use a simpler version of the training, first we need to set compile to false, this is also a must for Windows OS for now. We also set the device to CPU. The model that is trained in 10 minutes for a starter grade GPU, will be trained in a much longer time, so we can also decrease the dimensions of our model as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c42986c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"-1\"  # More reliable than empty string\n",
    "import torch\n",
    "torch.cuda.is_available = lambda: False  # Monkey-patch to always return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ef08093-984e-4fae-a1f9-fdf6bf4b1bd5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "!python train.py config/train_sentiment.py --device=cpu --out_dir=\"out-sentiment\" --compile=False --eval_iters=20 --log_interval=50 --block_size=64 --batch_size=12 --n_layer=4 --n_head=4 --n_embd=128 --max_iters=1000 --lr_decay_iters=1000 --dropout=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc8ca943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9b15c137-c810-495b-8962-573f7c4a7d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: sample.py [-h] [--out_dir OUT_DIR] [--checkpoint CHECKPOINT]\n",
      "sample.py: error: unrecognized arguments: --device=cpu\n"
     ]
    }
   ],
   "source": [
    "!python sample.py --out_dir=out-sentiment --device=cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "295012e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"  # More reliable than empty string\n",
    "import torch\n",
    "torch.cuda.is_available = lambda: True  # Monkey-patch to always return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebc70e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!set CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2e41b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5ae6eaff-1ca1-4791-a361-b9cef9b822a0",
   "metadata": {},
   "source": [
    "## The second model - Finetuning\n",
    "\n",
    "We will obtain the pre-trained model weights of gpt-2 and fine-tune it.\n",
    "Finetuning or transfer learning is a precious method of achieving better models thanks to pre-trained models. Finetuning GPT models is just as simple as training from scratch! We will now download the customer service (again) but this time we will define it with tokens (using OpenAI's BPE tokenizer) instead of characters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a84c540c-f048-446b-8cc8-214fffdb102d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train class distribution:\n",
      "sentiment\n",
      "1    542\n",
      "0    411\n",
      "2     17\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test class distribution:\n",
      "sentiment\n",
      "0    10\n",
      "1    10\n",
      "2    10\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Data processing complete:\n",
      "- Training samples: 776\n",
      "- Validation samples: 194\n",
      "- Test samples: 30\n",
      "Data saved to: c:\\Users\\nesil.bor\\Desktop\\Folders\\master\\DI725\\DI725-transformer-sentiment-analysis\\data\\sentiment\\processed\n",
      "\n",
      "Verifying saved files:\n",
      "- train.bin: 794624 bytes\n",
      "- val.bin: 198656 bytes\n",
      "- test.bin: 30720 bytes\n",
      "- train_labels.pkl: 928 bytes\n",
      "- val_labels.pkl: 342 bytes\n",
      "- test_labels.pkl: 178 bytes\n"
     ]
    }
   ],
   "source": [
    "!python data/sentiment/prepare.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039b052b-5c7d-4741-b3d5-217966d5ddf6",
   "metadata": {},
   "source": [
    "Run an example finetuning like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d0ba8e9-3977-43fd-b98d-a37b663d6010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loaded train dataset: 776 samples\n",
      "Loaded val dataset: 194 samples\n",
      "DataLoaders initialized\n",
      "WANDB initialized\n",
      "Loading weights from pretrained GPT: gpt2\n",
      "Number of parameters: 123.66M\n",
      "Model loaded and moved to cuda\n",
      "Froze all layers except sentiment_head and transformer.h.11\n",
      "Using fused AdamW: True\n",
      "Optimizer initialized\n",
      "Iter 0, Loss: 2.8826, Accuracy: 0.5000, Data: 0.021s, Forward: 0.292s, Backward: 0.117s, Total: 0.429s\n",
      "Validation Loss: 7.5610, Validation Accuracy: 0.1625\n",
      "Saved best model at iteration 0\n",
      "Iter 50, Loss: 3.6782, Accuracy: 0.5000, Data: 0.022s, Forward: 0.124s, Backward: 0.003s, Total: 0.149s\n",
      "Iter 100, Loss: 1.1516, Accuracy: 0.6250, Data: 0.023s, Forward: 0.126s, Backward: 0.004s, Total: 0.152s\n",
      "Validation Loss: 3.4223, Validation Accuracy: 0.4000\n",
      "Saved best model at iteration 100\n",
      "Iter 150, Loss: 0.7734, Accuracy: 0.7500, Data: 0.018s, Forward: 0.129s, Backward: 0.004s, Total: 0.152s\n",
      "Iter 200, Loss: 0.8302, Accuracy: 0.5000, Data: 0.023s, Forward: 0.126s, Backward: 0.003s, Total: 0.152s\n",
      "Validation Loss: 0.8140, Validation Accuracy: 0.4875\n",
      "Saved best model at iteration 200\n",
      "Iter 250, Loss: 1.1017, Accuracy: 0.5000, Data: 0.028s, Forward: 0.127s, Backward: 0.003s, Total: 0.158s\n",
      "Iter 300, Loss: 0.9397, Accuracy: 0.3750, Data: 0.028s, Forward: 0.125s, Backward: 0.003s, Total: 0.156s\n",
      "Validation Loss: 0.6656, Validation Accuracy: 0.6875\n",
      "Saved best model at iteration 300\n",
      "Iter 350, Loss: 0.4959, Accuracy: 0.7500, Data: 0.023s, Forward: 0.127s, Backward: 0.003s, Total: 0.152s\n",
      "Iter 400, Loss: 0.5207, Accuracy: 0.7500, Data: 0.024s, Forward: 0.129s, Backward: 0.003s, Total: 0.156s\n",
      "Validation Loss: 0.6665, Validation Accuracy: 0.6750\n",
      "Iter 450, Loss: 0.3184, Accuracy: 1.0000, Data: 0.020s, Forward: 0.129s, Backward: 0.003s, Total: 0.153s\n",
      "Iter 500, Loss: 0.6812, Accuracy: 0.6250, Data: 0.022s, Forward: 0.131s, Backward: 0.003s, Total: 0.156s\n",
      "Validation Loss: 0.6413, Validation Accuracy: 0.7125\n",
      "Saved best model at iteration 500\n",
      "Iter 550, Loss: 0.3977, Accuracy: 0.8750, Data: 0.023s, Forward: 0.127s, Backward: 0.003s, Total: 0.153s\n",
      "Iter 600, Loss: 0.4255, Accuracy: 1.0000, Data: 0.025s, Forward: 0.132s, Backward: 0.003s, Total: 0.160s\n",
      "Validation Loss: 0.6352, Validation Accuracy: 0.7000\n",
      "Saved best model at iteration 600\n",
      "Iter 650, Loss: 0.4201, Accuracy: 0.8750, Data: 0.023s, Forward: 0.127s, Backward: 0.005s, Total: 0.156s\n",
      "Iter 700, Loss: 0.5359, Accuracy: 0.7500, Data: 0.023s, Forward: 0.132s, Backward: 0.004s, Total: 0.159s\n",
      "Validation Loss: 0.6294, Validation Accuracy: 0.7000\n",
      "Saved best model at iteration 700\n",
      "Iter 750, Loss: 0.4013, Accuracy: 1.0000, Data: 0.021s, Forward: 0.133s, Backward: 0.005s, Total: 0.159s\n",
      "Iter 800, Loss: 0.6471, Accuracy: 0.5000, Data: 0.025s, Forward: 0.132s, Backward: 0.000s, Total: 0.157s\n",
      "Validation Loss: 0.6261, Validation Accuracy: 0.7125\n",
      "Saved best model at iteration 800\n",
      "Iter 850, Loss: 0.5923, Accuracy: 0.6250, Data: 0.023s, Forward: 0.131s, Backward: 0.001s, Total: 0.156s\n",
      "Iter 900, Loss: 0.4815, Accuracy: 0.6250, Data: 0.024s, Forward: 0.135s, Backward: 0.003s, Total: 0.162s\n",
      "Validation Loss: 0.6231, Validation Accuracy: 0.7000\n",
      "Saved best model at iteration 900\n",
      "Iter 950, Loss: 0.6593, Accuracy: 0.7500, Data: 0.022s, Forward: 0.133s, Backward: 0.003s, Total: 0.158s\n",
      "Training complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: Currently logged in as: adigew (adigew-middle-east-technical-university). Use `wandb login --relogin` to force relogin\n",
      "wandb: Tracking run with wandb version 0.18.7\n",
      "wandb: Run data is saved locally in c:\\Users\\nesil.bor\\Desktop\\Folders\\master\\DI725\\DI725-transformer-sentiment-analysis\\wandb\\run-20250405_165457-6ackvkhl\n",
      "wandb: Run `wandb offline` to turn off syncing.\n",
      "wandb: Syncing run andorian-first-contact-1\n",
      "wandb:  View project at https://wandb.ai/adigew-middle-east-technical-university/nanoGPT-sentiment-gpt2\n",
      "wandb:  View run at https://wandb.ai/adigew-middle-east-technical-university/nanoGPT-sentiment-gpt2/runs/6ackvkhl\n",
      "wandb: - 0.008 MB of 0.008 MB uploaded\n",
      "wandb: \\ 0.009 MB of 0.009 MB uploaded\n",
      "wandb: | 0.009 MB of 0.009 MB uploaded\n",
      "wandb:                                                                                \n",
      "wandb: \n",
      "wandb: Run history:\n",
      "wandb:      iteration ▁▁▁▂▂▂▂▂▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇███\n",
      "wandb:  learning_rate ▁▅████▇▇▆▆▅▅▄▄▃▃▂▂▂▂\n",
      "wandb: train_accuracy ▂▂▄▅▂▂▁▅▅█▄▇█▇▅█▂▄▄▅\n",
      "wandb:     train_loss ▆█▃▂▂▃▂▁▁▁▂▁▁▁▁▁▂▂▁▂\n",
      "wandb:   val_accuracy ▁▄▅███████\n",
      "wandb:       val_loss █▄▁▁▁▁▁▁▁▁\n",
      "wandb: \n",
      "wandb: Run summary:\n",
      "wandb:      iteration 950\n",
      "wandb:  learning_rate 0.0\n",
      "wandb: train_accuracy 0.75\n",
      "wandb:     train_loss 0.65929\n",
      "wandb:   val_accuracy 0.7\n",
      "wandb:       val_loss 0.62308\n",
      "wandb: \n",
      "wandb:  View run andorian-first-contact-1 at: https://wandb.ai/adigew-middle-east-technical-university/nanoGPT-sentiment-gpt2/runs/6ackvkhl\n",
      "wandb:  View project at: https://wandb.ai/adigew-middle-east-technical-university/nanoGPT-sentiment-gpt2\n",
      "wandb: Synced 4 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)\n",
      "wandb: Find logs at: .\\wandb\\run-20250405_165457-6ackvkhl\\logs\n"
     ]
    }
   ],
   "source": [
    "!python train_finetune.py --compile=False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9040fa6b-64a7-4964-afd5-3c5c545aeaba",
   "metadata": {},
   "source": [
    "This script fine-tunes a pre-trained GPT-2 model for a 3-class sentiment analysis task, adapting the language model for classification while preserving its core capabilities. The implementation builds a custom GPT architecture with key components like multi-head attention, layer normalization, and feed-forward networks, while adding a dedicated sentiment classification head on top of the transformer. It initializes with pre-trained GPT-2 weights (supporting various model sizes) and employs a strategic fine-tuning approach that freezes all layers except the last transformer block and the sentiment head, which receives a 10x higher learning rate to accelerate task-specific adaptation. The training process uses AdamW optimization with weight decay, cosine learning rate scheduling with warmup, and early stopping based on validation performance. The code handles batched training (batch size 8 due to memory constraints) on pre-processed sequences of length 512, with comprehensive logging of metrics like loss and accuracy through Weights & Biases. By maintaining most of the model's pre-trained weights while selectively fine-tuning the top layers, this approach efficiently adapts the powerful language model to the sentiment analysis task without losing its general language understanding capabilities. Model architecture is changable to `{'gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl'}`) and can be decreased in size by the `block_size` (context length). The best checkpoint (lowest validation loss) will be in the `out_dir` directory, e.g. in `out-sentiment-gpt2` by default, per the config file. You can then run the code in `sample_finetune.py --out_dir=out-sentiment-gpt2`:\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "97e567ad",
   "metadata": {},
   "source": [
    "# Inference and Sampling\n",
    "Use the script `sample_finetune.py` to sample either from pre-trained GPT-2 models released by OpenAI, or from a model you trained yourself. This script is designed to run sentiment prediction on a test dataset using a fine-tuned nanoGPT-style GPT-2 model. It loads a pre-trained model from a specified checkpoint and evaluates its performance on test data. The model architecture includes components like LayerNorm, CausalSelfAttention, and MLP, which are typical in transformer models. The script processes the test data, performs inference to predict sentiment labels (negative, neutral, positive), and compares these predictions to the true labels to calculate accuracy. The results, including the predicted and true sentiments for each sample, are printed out, along with a summary of the overall accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85d76c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from out-sentiment-gpt2\\best_model.pt and moved to cuda\n",
      "Loaded test dataset: 30 samples\n",
      "\n",
      "Sample 1:\n",
      "Text: thank you for calling brownbox customer support  my name is sarah  how may i assist you today? hi  s...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.338118314743042, 0.5629324316978455, 0.09894923865795135])\n",
      "True Sentiment: Negative\n",
      "\n",
      "Sample 2:\n",
      "Text: thank you for calling brownbox customer support  my name is sarah  how can i assist you today? hi sa...\n",
      "Predicted Sentiment: Negative (Probabilities: [0.5538395047187805, 0.3647975027561188, 0.08136302977800369])\n",
      "True Sentiment: Negative\n",
      "\n",
      "Sample 3:\n",
      "Text: thank you for calling brownbox customer support  my name is jane  how may i assist you today? hi jan...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.39019736647605896, 0.5070598721504211, 0.10274279117584229])\n",
      "True Sentiment: Negative\n",
      "\n",
      "Sample 4:\n",
      "Text: thank you for calling brownbox customer support  my name is sarah  how may i assist you today? hi sa...\n",
      "Predicted Sentiment: Negative (Probabilities: [0.828724205493927, 0.08432859927415848, 0.0869472324848175])\n",
      "True Sentiment: Negative\n",
      "\n",
      "Sample 5:\n",
      "Text: thank you for calling brownbox customer support  my name is sarah  how may i assist you today? hi sa...\n",
      "Predicted Sentiment: Negative (Probabilities: [0.5618094801902771, 0.3525823950767517, 0.0856081023812294])\n",
      "True Sentiment: Negative\n",
      "\n",
      "Sample 6:\n",
      "Text: thank you for calling brownbox customer support  my name is rachel  how may i assist you today? hi r...\n",
      "Predicted Sentiment: Negative (Probabilities: [0.6505793929100037, 0.29379215836524963, 0.05562840774655342])\n",
      "True Sentiment: Negative\n",
      "\n",
      "Sample 7:\n",
      "Text: thank you for calling brownbox customer support  my name is john  how may i assist you today? hi joh...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.4071499705314636, 0.49726808071136475, 0.095582015812397])\n",
      "True Sentiment: Negative\n",
      "\n",
      "Sample 8:\n",
      "Text: thank you for calling brownbox customer support  my name is alex  how may i assist you today? hi  al...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.43513450026512146, 0.4842338263988495, 0.08063171803951263])\n",
      "True Sentiment: Negative\n",
      "\n",
      "Sample 9:\n",
      "Text: hello  thank you for contacting brownbox customer support  how may i assist you today? hi  i am extr...\n",
      "Predicted Sentiment: Negative (Probabilities: [0.6265308856964111, 0.325696736574173, 0.04777234047651291])\n",
      "True Sentiment: Negative\n",
      "\n",
      "Sample 10:\n",
      "Text: thank you for calling brownbox customer support  my name is sarah  how may i assist you today? hi sa...\n",
      "Predicted Sentiment: Negative (Probabilities: [0.6629404425621033, 0.29208967089653015, 0.04496993124485016])\n",
      "True Sentiment: Negative\n",
      "\n",
      "Sample 11:\n",
      "Text: hello  i was looking to buy a vacuum cleaner from your website  but the one i want is currently out ...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.41972601413726807, 0.48373252153396606, 0.09654150158166885])\n",
      "True Sentiment: Neutral\n",
      "\n",
      "Sample 12:\n",
      "Text: thank you for calling brownbox customer support  my name is sarah  how may i assist you today? hi sa...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.43676507472991943, 0.4720895290374756, 0.09114543348550797])\n",
      "True Sentiment: Neutral\n",
      "\n",
      "Sample 13:\n",
      "Text: thank you for calling brownbox customer support  my name is emily  how may i assist you today? hi  e...\n",
      "Predicted Sentiment: Negative (Probabilities: [0.6561155319213867, 0.29632964730262756, 0.047554753720760345])\n",
      "True Sentiment: Neutral\n",
      "\n",
      "Sample 14:\n",
      "Text: thank you for contacting brownbox customer support  my name is john  how can i assist you today? hi ...\n",
      "Predicted Sentiment: Negative (Probabilities: [0.5450989007949829, 0.410786896944046, 0.044114187359809875])\n",
      "True Sentiment: Neutral\n",
      "\n",
      "Sample 15:\n",
      "Text: hi  i have a question about return checks and fees for a vacuum cleaner i returned  hello thank you ...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.24495239555835724, 0.6590198278427124, 0.09602774679660797])\n",
      "True Sentiment: Neutral\n",
      "\n",
      "Sample 16:\n",
      "Text: hello  thank you for calling brownbox customer support  my name is john  how may i assist you today?...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.37393489480018616, 0.5349048376083374, 0.09116023033857346])\n",
      "True Sentiment: Neutral\n",
      "\n",
      "Sample 17:\n",
      "Text: thank you for reaching out to brownbox customer support  how may i assist you today? hi  i received ...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.29621344804763794, 0.612967848777771, 0.09081867337226868])\n",
      "True Sentiment: Neutral\n",
      "\n",
      "Sample 18:\n",
      "Text: hello  thank you for calling brownbox customer support  my name is sarah  how may i assist you today...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.3974187672138214, 0.5058881640434265, 0.09669303894042969])\n",
      "True Sentiment: Neutral\n",
      "\n",
      "Sample 19:\n",
      "Text: thank you for calling brownbox customer support  my name is rachel  how may i assist you today? hi  ...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.30146968364715576, 0.6039143204689026, 0.09461601823568344])\n",
      "True Sentiment: Neutral\n",
      "\n",
      "Sample 20:\n",
      "Text: thank you for contacting brownbox customer support  my name is rachel  how may i assist you today? h...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.24588127434253693, 0.6531381011009216, 0.10098060965538025])\n",
      "True Sentiment: Neutral\n",
      "\n",
      "Sample 21:\n",
      "Text: thank you for calling brownbox customer support  my name is sarah  how can i assist you today? hi sa...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.2376631498336792, 0.6588977575302124, 0.10343904793262482])\n",
      "True Sentiment: Positive\n",
      "\n",
      "Sample 22:\n",
      "Text: thank you for calling brownbox customer support  my name is emily  how may i assist you today? hi em...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.3121474087238312, 0.5885896682739258, 0.09926290810108185])\n",
      "True Sentiment: Positive\n",
      "\n",
      "Sample 23:\n",
      "Text: thank you for calling brownbox customer support  my name is alex  how may i assist you today? hi ale...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.382445365190506, 0.5266079306602478, 0.09094668179750443])\n",
      "True Sentiment: Positive\n",
      "\n",
      "Sample 24:\n",
      "Text: thank you for calling brownbox customer support  my name is sarah  how can i assist you today? hi sa...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.30768638849258423, 0.5969604849815369, 0.09535317122936249])\n",
      "True Sentiment: Positive\n",
      "\n",
      "Sample 25:\n",
      "Text: hi  i placed an order for a vacuum cleaner yesterday  and i just wanted to confirm the order status ...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.2116207629442215, 0.6876304745674133, 0.10074872523546219])\n",
      "True Sentiment: Positive\n",
      "\n",
      "Sample 26:\n",
      "Text: hi  i'm calling to inquire about my order status for a smart band i purchased from brownbox  hello t...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.2258690744638443, 0.6797139644622803, 0.09441699087619781])\n",
      "True Sentiment: Positive\n",
      "\n",
      "Sample 27:\n",
      "Text: thank you for calling brownbox customer support  my name is john  how may i assist you today? hi joh...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.2759120464324951, 0.6303912401199341, 0.09369673579931259])\n",
      "True Sentiment: Positive\n",
      "\n",
      "Sample 28:\n",
      "Text: hi there  i'm interested in purchasing a dslr camera from your website  but i'm having trouble findi...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.30230462551116943, 0.6006924510002136, 0.09700288623571396])\n",
      "True Sentiment: Positive\n",
      "\n",
      "Sample 29:\n",
      "Text: thank you for calling brownbox customer support  my name is sarah  how may i assist you today? hi sa...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.2320365458726883, 0.6716456413269043, 0.09631785750389099])\n",
      "True Sentiment: Positive\n",
      "\n",
      "Sample 30:\n",
      "Text: thank you for calling brownbox customer support  this is john  how may i assist you today? hi john  ...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.331075519323349, 0.5744422078132629, 0.09448225796222687])\n",
      "True Sentiment: Positive\n",
      "\n",
      "Summary: 14/30 correct, Test Accuracy: 0.4667 (46.67%)\n"
     ]
    }
   ],
   "source": [
    "!python sample_finetune.py --out_dir=out-sentiment-gpt2 --checkpoint=best_model.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe10349f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from out-sentiment-gpt2\\final_model.pt and moved to cuda\n",
      "Loaded test dataset: 30 samples\n",
      "\n",
      "Sample 1:\n",
      "Text: thank you for calling brownbox customer support  my name is sarah  how may i assist you today? hi  s...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.3347285985946655, 0.5667935609817505, 0.0984777882695198])\n",
      "True Sentiment: Negative\n",
      "\n",
      "Sample 2:\n",
      "Text: thank you for calling brownbox customer support  my name is sarah  how can i assist you today? hi sa...\n",
      "Predicted Sentiment: Negative (Probabilities: [0.5547237396240234, 0.36500921845436096, 0.0802670568227768])\n",
      "True Sentiment: Negative\n",
      "\n",
      "Sample 3:\n",
      "Text: thank you for calling brownbox customer support  my name is jane  how may i assist you today? hi jan...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.3887985646724701, 0.5090003609657288, 0.10220105946063995])\n",
      "True Sentiment: Negative\n",
      "\n",
      "Sample 4:\n",
      "Text: thank you for calling brownbox customer support  my name is sarah  how may i assist you today? hi sa...\n",
      "Predicted Sentiment: Negative (Probabilities: [0.8334356546401978, 0.08282177150249481, 0.08374260365962982])\n",
      "True Sentiment: Negative\n",
      "\n",
      "Sample 5:\n",
      "Text: thank you for calling brownbox customer support  my name is sarah  how may i assist you today? hi sa...\n",
      "Predicted Sentiment: Negative (Probabilities: [0.5594819784164429, 0.35602688789367676, 0.08449114859104156])\n",
      "True Sentiment: Negative\n",
      "\n",
      "Sample 6:\n",
      "Text: thank you for calling brownbox customer support  my name is rachel  how may i assist you today? hi r...\n",
      "Predicted Sentiment: Negative (Probabilities: [0.6549041867256165, 0.29069992899894714, 0.0543958954513073])\n",
      "True Sentiment: Negative\n",
      "\n",
      "Sample 7:\n",
      "Text: thank you for calling brownbox customer support  my name is john  how may i assist you today? hi joh...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.4040238559246063, 0.5011591911315918, 0.09481693804264069])\n",
      "True Sentiment: Negative\n",
      "\n",
      "Sample 8:\n",
      "Text: thank you for calling brownbox customer support  my name is alex  how may i assist you today? hi  al...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.4424627721309662, 0.4772905707359314, 0.08024664968252182])\n",
      "True Sentiment: Negative\n",
      "\n",
      "Sample 9:\n",
      "Text: hello  thank you for contacting brownbox customer support  how may i assist you today? hi  i am extr...\n",
      "Predicted Sentiment: Negative (Probabilities: [0.6288474798202515, 0.3242105543613434, 0.046941932290792465])\n",
      "True Sentiment: Negative\n",
      "\n",
      "Sample 10:\n",
      "Text: thank you for calling brownbox customer support  my name is sarah  how may i assist you today? hi sa...\n",
      "Predicted Sentiment: Negative (Probabilities: [0.6647025942802429, 0.2911827862262726, 0.044114675372838974])\n",
      "True Sentiment: Negative\n",
      "\n",
      "Sample 11:\n",
      "Text: hello  i was looking to buy a vacuum cleaner from your website  but the one i want is currently out ...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.4179551899433136, 0.4861370623111725, 0.0959077924489975])\n",
      "True Sentiment: Neutral\n",
      "\n",
      "Sample 12:\n",
      "Text: thank you for calling brownbox customer support  my name is sarah  how may i assist you today? hi sa...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.4380801022052765, 0.4716583490371704, 0.09026160091161728])\n",
      "True Sentiment: Neutral\n",
      "\n",
      "Sample 13:\n",
      "Text: thank you for calling brownbox customer support  my name is emily  how may i assist you today? hi  e...\n",
      "Predicted Sentiment: Negative (Probabilities: [0.659212052822113, 0.2941669523715973, 0.046620965003967285])\n",
      "True Sentiment: Neutral\n",
      "\n",
      "Sample 14:\n",
      "Text: thank you for contacting brownbox customer support  my name is john  how can i assist you today? hi ...\n",
      "Predicted Sentiment: Negative (Probabilities: [0.5460121631622314, 0.4106365144252777, 0.04335130378603935])\n",
      "True Sentiment: Neutral\n",
      "\n",
      "Sample 15:\n",
      "Text: hi  i have a question about return checks and fees for a vacuum cleaner i returned  hello thank you ...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.24233315885066986, 0.66207355260849, 0.09559327363967896])\n",
      "True Sentiment: Neutral\n",
      "\n",
      "Sample 16:\n",
      "Text: hello  thank you for calling brownbox customer support  my name is john  how may i assist you today?...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.36991408467292786, 0.5395907759666443, 0.09049510210752487])\n",
      "True Sentiment: Neutral\n",
      "\n",
      "Sample 17:\n",
      "Text: thank you for reaching out to brownbox customer support  how may i assist you today? hi  i received ...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.2933613359928131, 0.6162429451942444, 0.09039575606584549])\n",
      "True Sentiment: Neutral\n",
      "\n",
      "Sample 18:\n",
      "Text: hello  thank you for calling brownbox customer support  my name is sarah  how may i assist you today...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.3937312662601471, 0.5103622078895569, 0.09590653330087662])\n",
      "True Sentiment: Neutral\n",
      "\n",
      "Sample 19:\n",
      "Text: thank you for calling brownbox customer support  my name is rachel  how may i assist you today? hi  ...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.2981629967689514, 0.6077585816383362, 0.09407838433980942])\n",
      "True Sentiment: Neutral\n",
      "\n",
      "Sample 20:\n",
      "Text: thank you for contacting brownbox customer support  my name is rachel  how may i assist you today? h...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.24346023797988892, 0.6559320092201233, 0.10060781985521317])\n",
      "True Sentiment: Neutral\n",
      "\n",
      "Sample 21:\n",
      "Text: thank you for calling brownbox customer support  my name is sarah  how can i assist you today? hi sa...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.23545975983142853, 0.6614682674407959, 0.10307201743125916])\n",
      "True Sentiment: Positive\n",
      "\n",
      "Sample 22:\n",
      "Text: thank you for calling brownbox customer support  my name is emily  how may i assist you today? hi em...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.3094860911369324, 0.5917218923568726, 0.09879200160503387])\n",
      "True Sentiment: Positive\n",
      "\n",
      "Sample 23:\n",
      "Text: thank you for calling brownbox customer support  my name is alex  how may i assist you today? hi ale...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.3785552382469177, 0.5311688780784607, 0.09027589112520218])\n",
      "True Sentiment: Positive\n",
      "\n",
      "Sample 24:\n",
      "Text: thank you for calling brownbox customer support  my name is sarah  how can i assist you today? hi sa...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.3045097291469574, 0.6007041931152344, 0.09478604793548584])\n",
      "True Sentiment: Positive\n",
      "\n",
      "Sample 25:\n",
      "Text: hi  i placed an order for a vacuum cleaner yesterday  and i just wanted to confirm the order status ...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.20976871252059937, 0.6898638010025024, 0.1003674864768982])\n",
      "True Sentiment: Positive\n",
      "\n",
      "Sample 26:\n",
      "Text: hi  i'm calling to inquire about my order status for a smart band i purchased from brownbox  hello t...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.22353841364383698, 0.6824770569801331, 0.09398453682661057])\n",
      "True Sentiment: Positive\n",
      "\n",
      "Sample 27:\n",
      "Text: thank you for calling brownbox customer support  my name is john  how may i assist you today? hi joh...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.27261584997177124, 0.6342191696166992, 0.09316501766443253])\n",
      "True Sentiment: Positive\n",
      "\n",
      "Sample 28:\n",
      "Text: hi there  i'm interested in purchasing a dslr camera from your website  but i'm having trouble findi...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.29900088906288147, 0.6045783758163452, 0.0964207872748375])\n",
      "True Sentiment: Positive\n",
      "\n",
      "Sample 29:\n",
      "Text: thank you for calling brownbox customer support  my name is sarah  how may i assist you today? hi sa...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.22971764206886292, 0.6743226051330566, 0.09595977514982224])\n",
      "True Sentiment: Positive\n",
      "\n",
      "Sample 30:\n",
      "Text: thank you for calling brownbox customer support  this is john  how may i assist you today? hi john  ...\n",
      "Predicted Sentiment: Neutral (Probabilities: [0.32799437642097473, 0.5779800415039062, 0.09402555972337723])\n",
      "True Sentiment: Positive\n",
      "\n",
      "Summary: 14/30 correct, Test Accuracy: 0.4667 (46.67%)\n"
     ]
    }
   ],
   "source": [
    "!python sample_finetune.py --out_dir=out-sentiment-gpt2 --checkpoint=final_model.pt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2e9c0355-3e89-4ea0-9976-411dc15d76e5",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Acknowledgements\n",
    "\n",
    "This code is a fork from Andrej Karpathy's introductory [NanoGPT repository](https://github.com/karpathy/nanoGPT), which is an updated form of minGPT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d4e757-8a74-40bf-a36c-9b5f59135121",
   "metadata": {},
   "source": [
    "# Further Experiments\n",
    "\n",
    "(Optional)\n",
    "\n",
    "For further experiments, you can, for example, reproduce the GPT-2, which is still powerful, by following the link to the Andrej Karpathy's repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6ce869-04d3-4278-a449-a0c8edb1807b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
